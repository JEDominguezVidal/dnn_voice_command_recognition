#!/usr/bin/env python
PACKAGE = "dnn_voice_command_recognition"

from dynamic_reconfigure.parameter_generator_catkin import *

gen = ParameterGenerator()

gen.add("rate",         		double_t, 0, "Main thread rate",     10,  1, 100)
gen.add("debug",   			bool_t,   0, "Activate to print debug messages",  False)
gen.add("prob_threshold",         	double_t, 0, "Minimum probaability to accept a prediction as valid",     0.9,  0.1, 1.0)
gen.add("SAMPLING_RATE",    		int_t,    0, "Audio's sampling rate. Model trained with 16000 Hz", 16000,  100, 20000)
gen.add("FRAMES_PER_BUFFER",    	int_t,    0, "Number of samples from one batch to the next one", 4000,  100, 20000)

model_enum = gen.enum([ gen.const("8_labels_Small",      int_t, 0, "CNN-based (small) model recognizing 8 labels"),
                       gen.const("8_labels_Medium",     int_t, 1, "CNN-based (medium) model recognizing 8 labels"),
                       gen.const("12_labels_Small",     int_t, 2, "CNN-based (small) model recognizing 12 labels"),
                       gen.const("12_labels_Medium",     int_t, 3, "CNN-based (medium) model recognizing 12 labels"),
                       gen.const("35_labels_Small",     int_t, 4, "CNN-based (small) model recognizing 35 labels"),
                       gen.const("35_labels_Medium",     int_t, 5, "CNN-based (medium) model recognizing 35 labels"),
                       gen.const("35_labels_Large",      int_t, 6, "ResNet-based (large) model recognizing 35 labels")],
                     "Select desired model")

gen.add("model", 			int_t, 0, "Selected model", 0, 0, 6, edit_method=model_enum)

exit(gen.generate(PACKAGE, "dnn_voice_command_recognition", "Node"))
